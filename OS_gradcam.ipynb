{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OS_gradcam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkQem2mrPiizju5ZwfieTx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xMhZSpi1ipZ"
      },
      "source": [
        "import os\n",
        "code_path = os.getcwd()\n",
        "data_path = code_path + 'Original X-ray Image Dataset'\n",
        "covid_path = data_path + '/covid/'\n",
        "none_path = data_path + '/none/'\n",
        "pneumonia_path = data_path + '/pneumonia/'\n",
        "print(len(os.listdir(covid_path))) #125\n",
        "print(len(os.listdir(none_path))) #500\n",
        "print(len(os.listdir(pneumonia_path))) #500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B-gZI_O1ozA"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "import matplotlib.image as mpimg\n",
        "from keras_preprocessing.image import img_to_array\n",
        "import PIL\n",
        "import numpy as np\n",
        "import keras.preprocessing.image\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJrV4qro1s6R"
      },
      "source": [
        "def makemodel(k):\n",
        "      global model\n",
        "      K.clear_session()\n",
        "      model_input = layers.Input(shape = (256,256,3))\n",
        "      x = layers.Conv2D(8, 3, 1, padding='same', use_bias=False)(model_input)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.MaxPooling2D((2,2),strides=2)(x)\n",
        "      x = layers.Conv2D(16, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.MaxPooling2D((2,2),strides=2)(x)\n",
        "      x = layers.Conv2D(32, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.ZeroPadding2D(((2,0),(2,0)))(x)\n",
        "      x = layers.Conv2D(16, 1, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(32, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.MaxPooling2D((2,2),strides=2)(x)\n",
        "      x = layers.Conv2D(64, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.ZeroPadding2D(((2,0),(2,0)))(x)\n",
        "      x = layers.Conv2D(32, 1, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(64, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.MaxPooling2D((2,2),strides=2)(x)\n",
        "      x = layers.Conv2D(128, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.ZeroPadding2D(((2,0),(2,0)))(x)\n",
        "      x = layers.Conv2D(64, 1, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(128, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.MaxPooling2D((2,2),strides=2)(x)\n",
        "      x = layers.Conv2D(256, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.ZeroPadding2D(((2,0),(2,0)))(x)\n",
        "      x = layers.Conv2D(128, 1, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(256, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.ZeroPadding2D(((2,0),(2,0)))(x)\n",
        "      x = layers.Conv2D(128, 1, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(256, 3, 1, padding='same', use_bias=False)(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "      x = layers.Conv2D(k, k, 1, padding=\"same\")(x)\n",
        "      x = layers.ReLU()(x)\n",
        "      x = layers.BatchNormalization()(x)\n",
        "      x_ls = layers.Flatten()(x)\n",
        "      \n",
        "      \"orthogonal constraint\"\n",
        "      ls_split_dim = k\n",
        "      x_ls_norm = layers.Lambda(lambda t: K.l2_normalize(t, axis=1))(x_ls)\n",
        "      ls_split = layers.Lambda(lambda tensor: tf.split(tensor, [int(K.int_shape(x_ls)[1]/ls_split_dim)]*ls_split_dim,axis=1))(x_ls_norm)\n",
        "      ls_stack = layers.Lambda(lambda tensor: tf.stack(tensor, axis=2))(ls_split)\n",
        "      ls_utu = layers.Lambda(lambda tensor: tf.linalg.matmul(tensor,tensor,transpose_a=True))(ls_stack)\n",
        "      ls_utu_diag = layers.Lambda(lambda tensor: tf.compat.v1.matrix_diag_part(tensor)-1)(ls_utu)\n",
        "      ls_utu2 = layers.Lambda(lambda tensor: tf.compat.v1.matrix_set_diag(tensor,ls_utu_diag))(ls_utu)\n",
        "      l_orths = layers.Lambda(lambda tensor: K.sqrt(K.sum(K.square(tensor),axis=[1,2])))(ls_utu2)\n",
        "      l_orths = layers.Reshape((1,))(l_orths)\n",
        "      model_output = layers.Dense(3, activation=\"softmax\")(x_ls)\n",
        "      model = Model(model_input, [model_output, l_orths])\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX2lWBSz1_h_"
      },
      "source": [
        "def image_preprocessing(image_path):\n",
        "  image_loaded=tf.python.keras.preprocessing.image.load_img(image_path, color_mode='rgb', \n",
        "  target_size= (256,256))\n",
        "  image_loaded=np.asarray(image_loaded)\n",
        "  image = image_loaded.astype('float32')/255\n",
        "  image = img_to_array(image)\n",
        "  x = np.expand_dims(image, axis=0)\n",
        "  image_class = np.argmax(image_class_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSQha1rx1yKV"
      },
      "source": [
        "def get_activation_map(image_path, image_class_vector, img_size):        \n",
        "        image_preprocessing(image_path)\n",
        "        makemodel(k)\n",
        "\n",
        "        model.load_weights(dataset_path+'OS-model-weights.h5')\n",
        "        class_weights = model.layers[-2].get_weights()[0]\n",
        "        final_conv_layer = model.layers[-12]\n",
        "\n",
        "        get_output = tf.keras.backend.function([model.layers[0].input], \n",
        "                                               [final_conv_layer.output, model.layers[-2].output])\n",
        "        [conv_outputs, predictions] = get_output(x)\n",
        "\n",
        "        conv_outputs = conv_outputs[0, :, :, :]\n",
        "\n",
        "        cam = np.zeros(dtype=np.float32, shape=conv_outputs.shape[0:2])\n",
        "\n",
        "        for index, weight in enumerate(class_weights[:, image_class]):\n",
        "          if index<=2:\n",
        "            cam += weight * conv_outputs[:, :, index]\n",
        "\n",
        "        preds = predictions.argmax(axis=1)[0]\n",
        "        files.append([image_path, np.max(predictions), preds])\n",
        "        class_predicted = preds\n",
        "        predictions = f'Class predicted: {class_predicted} | Real class: {image_class}'\n",
        "        \n",
        "        cam /= np.max(cam)\n",
        "        cam = cv2.resize(cam, (img_size, img_size))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "        heatmap[np.where(cam < 0.01)] = 0\n",
        "        \n",
        "        img = heatmap * 0.5 + image_loaded\n",
        "        cv2.imwrite(\"heatmap.jpg\", img)\n",
        "        \n",
        "        heatmap = mpimg.imread(\"heatmap.jpg\")\n",
        "        \n",
        "        scaled_image = (((img - img.min())) / (img.max() - img.min())).astype(np.uint8)\n",
        "        \n",
        "        fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "        ax[0].imshow(image_loaded)\n",
        "\n",
        "        ax[0].set_title('Original image')\n",
        "\n",
        "        ax[1].imshow(heatmap)\n",
        "        ax[1].set_title(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3dzU-h2n2M"
      },
      "source": [
        "def gradcam(vector, path):\n",
        "  files = os.listdir(path)\n",
        "  y = 0\n",
        "  while y<len(files):\n",
        "    img = files[y]\n",
        "    img_path = path + img\n",
        "    get_activation_map(img_path,vector,256)\n",
        "    y+=1\n",
        "\n",
        "print(\"COVID\")\n",
        "gradcam(vector=[1,0,0], path=covid_path)\n",
        "print(\"None\")\n",
        "gradcam(vector=[0,1,0], path=none_path)\n",
        "print(\"Pneumonia\")\n",
        "gradcam(vector=[0,0,1], path=pneumonia_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}